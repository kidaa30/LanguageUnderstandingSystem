# First Mid-Term Project

## Overview
This is the first mid-term project for the course of Language Understanding Systems.

Author: [Alessio Bogon](https://twitter.com/youtux).

## [Long story short: usage](id:usage)
In order to run the program, you need to have either:

* in **atis/custom.wl** the file containing the sentences to test, or
* in **atis/custom.tagged**[^1] the test file with concept tags.

In case you want use the first one, just type 

	make from_wl
Otherwise if you chose the latter, just type

	make from_tagged

In either ways you will find in **build/output.txt** the output file generated by the program, and in case you chose to give the reference file as input, you'll find also in **build/comparison.txt** a comparison of them with the calculated CER.

As we will see later, some of the finite state machines are dynamically generated by a script. In order to generate the source code for these automatons you will need to call

	make parser
	
[^1]: The tagged/reference file must agree to a two-columns style, the first containing one word of the utterance and the second containing the associated concept. Sentences must be separated with a blank new-line. See **atis/atis.hlti.100.dev** for reference.

## [Description](id:description)
The main steps that have been followed in order to build the project are the following:

* Understand the training set to get an overview of the concepts we want to recognize
* Write a first draw of the grammar
* Write a python script (**scripts/build_parser.py**) that creates the w2c.fst (word2concepts finite state transducer) starting from concept dictionaries (see [later](#w2c))
* Refine the grammar and the python script until results are satisfying

In order to automate the procedure of tagging a sentence, the project uses a combination of *Makefile*, *python* scripts, [*fsm*](http://www2.research.att.com/~fsmtools/fsm/) and [*grm*](http://www2.research.att.com/~fsmtools/grm/) tools by *AT&T*. This tools will help us to build three final state machines:

* **w2c.fst**, the one that converts words (both known and unknown) to concepts
* **slu.fsa**, the acceptor generated by the grammar,
* **null.fst**, the transducer that convert words that are no more useful to *null*

In a nutshell, the **Makefile** will:

* build the *fsm*s and pack them in **tagger.fst**
* take the input list of utterances, convert everyone in the corresponding *fsa* and pack them into one big file using `farcompilestrings`.
* Compose every single utterance with the **tagger.fst** and put the result into another *fararchive* (*output.far*).
* Compare the reference file (if available) with the generated one, and show the results.

### [Words to concepts conversion](id:w2c)
The file **build/w2c.txt** is the source code of the transducer that maps words to concepts (e.g. *dallas* to *city_name*, *fromloc.city_name*, *toloc.city_name*, ...). In order to create it, we use a python script, **scripts/build_parser.py** that uses a knowledge base of concepts: in the **dictionaries/concepts/** directory there are plenty of files, for instance **city_name.txt**. When the **build_parser.py** is invoked, it reads every file from this directory[^2], and if the filename matches one of the concepts, all the lines in the file will be mapped to that concept.

For instance, if the content of the file **dictionaries/concepts/city_name.txt** is

	dallas
	denver
	san-francisco
then these lines will be mapped to the right concepts[^3] in the **w2c.txt** source code:

	0	0	dallas	stoploc.city_name	0
	0	0	dallas	fromloc.city_name	0
	0	0	dallas	toloc.city_name	0
	0	0	dallas	dallas	0
	0	0	dallas	city_name	0
	0	0	dallas	null	4
	0	0	denver	stoploc.city_name	0
	...
**w2c.txt** is generated using also another dictionary, **dictionaries/basic_words.txt**. This one only has words that are meaningful to the grammar in order to take a decision, but they will be mapped to null once the *best path* has been chosen.

Another important thing is the handling of *unknown* words. We don't know anything about that these words and they can be anything: an airport, a city, a date, a mistake, gibberish, etc. Due to this unpredictability we map the *unknown* to all the possible concepts, including of course *null*. When doing this we use different weights and we can see them in the **build_parser.py** script:

	def words2concepts(...):
	    # define weights
	    w = {
	        'unk2concepts': 4,
	        'unk2null': 2,
	        'basic2null': 5,
	        'concepts2null': 4,
	    }
	    ...
 	    
As we can see, *unknown* words are mapped to concepts with weight 4, and to *null* with weight 2. This has been done since once we have a big-enough knowledge base it is more likely that something is useless (i.e. *null*) rather than a useful concept.

There are other weights declared, but these are just selected to fine-grain the accuracy of the system.

[^2]: Actually, **build_parser.py** only looks for filenames that doesn't end with `.ignore`
[^3]: Every word is also mapped to itself and to null. To itself because we may want to handle special names in our grammar. For instance, `the` can be the article or can be the IATA code for the [Teresina Airport](http://en.wikipedia.org/wiki/Teresina_Airport). To null because we may want to ignore the word. Note that these actions have different weights.

### [The Grammar](id:grammar)
The grammar that will take the decision for the right tag is located in **automatons/slu.txt**. The grammar is meant to cover a big portion of the utterances given in the development and test sets. Many concepts are not implemented to keep the grammar readable and not overkilling in terms of computation time. Keep in mind that `grm` tools allow only regular grammar, so we don't expect to have the power of a real context-free grammar.

The idea used to build the grammar is that we want to accept every utterance and that we want to be as much flexible as possible when tagging.

For example, the purpose of the lines[^4]

	S					0 <eps>
	S					0 GARBAGE S
	...
	GARBAGE				0 GARBAGE_S GARBAGE | 0 <eps>
	GARBAGE_S			1 null | 0 what | 0 which | 0 like to | ...
is to accept everything in the worst case, since all the words are mapped to null by the *w2c*. Note that when reading a *null* word we increase the weight by 1, since we want to treat a word as *null* if no other paths are possible.

[^4]: The `GARBAGE_S` non-terminal is a single part of useless words (e.g. *the*, *what*, *like to*, etc.), while `GARBAGE` is zero or more of `GARBAGE_S`.

The lines

	S					0 leaving FROMLOC for TOLOC S | 0 between FROMLOC and TOLOC S  | 0 from FROMLOC to STOPLOC to TOLOC S
	S					0 FROM_SEP FROMLOC TO_SEP TOLOC S
	
are straight forward: they will tag utterances like `show me the flights leaving boston for denver` or `flights between san-francisco and new-york` or `from miami to los-angeles`, and they are probably the most used production rules during the tagging process.

Then we have a more general production

	S					0 START_STMT GARBAGE START_FRAME S
	S					0 ARRIVE_STMT GARBAGE ARRIVE_FRAME S
	S					0 STOP_STMT GARBAGE STOP_FRAME S
	S					1 RETURN_STMT GARBAGE RETURN_FRAME S

that will parse *frames* of the utterance that are respectively informations about *leaving*, *arriving*, *stop* and *return*. Note that we get to the `RETURN_FRAME` with cost 1, since it is less likely to have *return* informations rather than *arrive* informations.

We can now jump to the `START_FRAME` productions:

	START_FRAME			0 FROM_SEP FROMLOC START_FRAME_CONT
	START_FRAME			0 LEAVING_TIME START_FRAME_CONT
	START_FRAME			0 LEAVING_DATE START_FRAME_CONT
	START_FRAME_CONT	0 START_FRAME START_FRAME_CONT | 0 <eps>

Once we get to the `START_FRAME`, we may read a `FROM_SEP` and then we'll wait for a location, or we can read something related to the time/date and go into the `LEAVING_TIME`/`_DATE`. In both ways, thanks to the `START_FRAME_CONT` rule we can either keep staying in the frame or exit from it using the `<eps>` shortcut. This allow us to read further informations that should be treated as *leaving* informations. The same goes for `ARRIVE_FRAME` and `RETURN_FRAME`.

All the other production rules are probably not worth the time to be explained, since they are pretty simple.

## [Results](id:results)
The output of the program can be found in two forms:

* **build/output.far** in form of a *fararchive*
* **build/output.txt** in form of two-columns plain text (just like the tagged-input one)

If we want to compare the result with the reference file there is a script, **compare_outputs.py**, that compares tagged utterances one by one, using the CER. Note that we use the *strong* version of the CER: all the tags are considered in the evaluation, including null, and the order matters. For instance, if we have something like:

Input        | Reference             | Output
------------ | -----------------     | -----------------
flights      | null                  | null
from         | **null**              | **fromloc.city_name**
dallas       | **fromloc.city_name** | **null**
to           | null                  | null
san-francisco| toloc.city_name       | toloc.city_name

the CER will be 2/5, since we have 2 unaligned concepts on rows 2 and 3.

The result of the comparison is stored in **build/comparison.txt**. At the end of the file we will see two lines like the followings:

	{'sum_n_concepts': 8333, 'sum_edit_d': 487}
	CER_total=0.0584423376935

The `sum_n_concepts` variable stores the total number of words, while `sum_edit_d` accumulates the edit distance of all the utterances.
`CER_total` is the weighted average of all the calculated *CER*s.

In the following table we can find the results obtained using the development set and the test set:

File name         | Computation time | Total CER
----------------- | ---------------- | ---------------
atis.hlti.100.dev | 1:22,53          | 0.00728
atis.test         | 12:12,69         | 0.05844

Unfortunately the computation time is pretty long and this is partially due to the fact that after the *w2c* conversion every word assumes non-deterministically many concepts. A solution to this problem will be described in the next paragraph.

## [Further work and optimisation](id:furtherwork)
The heavy computation time is due to the fact that every input word is converted in all the possible concepts (with different weights of course) in order to get a good flexibility.

If we have a very good knowledge base of all the possible airports, cities, etc. we can avoid to map every word to all the concepts, and map it only to the matching ones.

Furthermore, another optimisation would be to pre-process the utterances by recognizing numbers like times, dates, flight numbers, etc. using a regular expression. For instance, instead of having a 1540-lines dictionary for the `time` concept, a simple regular expression would be much more efficient. 