# First Mid-Term Project
## Overview
This is the first mid-term project for the course of Language Understanding Systems.

Author: [Alessio Bogon](https://twitter.com/youtux).
## Long story short: usage
In order to run the program, you need to have either:

* in **atis/custom.wl** the file containing the sentences to test, or
* in **atis/custom.tagged**[^1] the test file with concept tags.

In case you want use the first one, just type 

	make from_wl
Otherwise if you chose the latter, just type

	make from_tagged

In either ways you will find in **build/tagged.txt** the tagged file generated by the program, and in case you chose to give the reference file as input, you'll find also in **build/comparison.txt** a comparison complete with CER.

[^1]: The tagged/reference file must agree to a two-columns style, the first containing the words, the second containing the concepts. Each sentence must be terminated with a blank new-line. See **atis/atis.hlti.100.dev** for reference.

## Description
The main steps I followed in order to build the project are the following:

* Understand the training set to get an overview of the concepts we want to recognize
* Write a first draw of the grammar
* Write a python script (**scripts/build_parser.py**) that creates the w2c.fst (word2concepts finite state transducer) starting from concept dictionaries (see later)
* Refine the grammar and the python script until results are satisfying

In order to automatize the procedure of tagging a sentence, the project uses a combination of *Makefile*, *python* scripts, *fsm* and *grm* tools by *AT&T*. This tools will help us to build three final state machines:

* **w2c.fst**, the one that converts words (both known and unknown) to concepts
* **slu.fsa**, the acceptor generated by the grammar,
* **null.fst**, the transducer that convert words that are no more useful to *null*

In a nutshell, the **Makefile** will:

* build the *fsm*s and pack them in **tagger.fst**
* take the input list of utterances, convert everyone in the corresponding *fsa* and pack them into one big file using `farcompilestrings`.
* Compose every single utterance with the **tagger.fst** and put the result into another *fararchive* (*output.far*).
* Compare the reference file (if present) with the generated one, and show the results.

Let's see how the w2c transducer works.

### word2concepts transducer
The file **build/w2c.txt** is the source code of the transudcer that maps words to concepts (ie. *dallas* to *city_name*, *fromloc.city_name*, *toloc.city_name*, ...). In order to create it, we use a python script, **scripts/build_parser.py** that use a knowledge base of concepts: in the **dictionaries/concepts/** directory there are plenty of files, for instance **city_name.txt**. When the **build_parser.py** is invoked, it reads every file from this directory[^2], and if the filename matches one of the concepts, all the lines in the file will be mapped to the correct concepts.
For instance, if the content of the file **dictionaries/concepts/city_name.txt** is

	dallas
	denver
	san-francisco
then these lines will be mapped to the right concepts[^3] in the **w2c.txt** source code:

	0	0	dallas	stoploc.city_name	0
	0	0	dallas	fromloc.city_name	0
	0	0	dallas	toloc.city_name	0
	0	0	dallas	dallas	0
	0	0	dallas	city_name	0
	0	0	dallas	null	4
	0	0	denver	stoploc.city_name	0
	...
**w2c.txt** is generated using also another dictionary, **dictionaries/basic_words.txt**. This one only has words that are meaningful to the grammar in order to take a decision, but they will be mapped to null once the *best path* has been chosen.

[^2]: Actually, **build_parser.py** only looks for filenames that doesn't end with `.ignore`
[^3]: Every word is also mapped to itself and to null. To itself because we may want to handle special names in our grammar. For instance, `the` can be the article or can be the IATA code for the [Teresina Airport](http://en.wikipedia.org/wiki/Teresina_Airport). To null because we may want to ignore the word. Note that these actions have different weights.

## The Grammar